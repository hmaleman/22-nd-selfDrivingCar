{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to TensorFlow\n",
    "- Course: Self Driving Car Nanodegree\n",
    "- Lesson 6: Intro to TensorFlow\n",
    "- Topic: Basic math operations for Neural Networks with TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and variable initialization\n",
    "tf.constant() and tf.placeholder() instantiate tensors which can not be modified. For modifiable tensors, the used class is **tf.Variable**.\n",
    "\n",
    "The **tf.global_variables_initializer()** funcion initializes the state of all variable tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(5) # 5 is defined as initial value\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    getX = sess.run(x)\n",
    "    print(getX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights init with randon numbers from normal distribution\n",
    "For the case of variables initialization, in this case the weights matrix, with randon numbers on normal distribution, TF provides the function: **tf.truncated_normal()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n",
      "[[-1.23768318 -1.14573717]\n",
      " [ 0.46240932 -0.19823064]\n",
      " [-0.23971376 -1.10599101]]\n",
      "Bias\n",
      "[ 0.  0.]\n"
     ]
    }
   ],
   "source": [
    "n_features = 3\n",
    "n_labels = 2\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "bias = tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    getW = sess.run(weights)\n",
    "    print(\"Weights\")\n",
    "    print(getW)\n",
    "    getB = sess.run(bias)\n",
    "    print(\"Bias\")\n",
    "    print(getB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66524096  0.09003057  0.24472847]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    eX = np.exp(x)\n",
    "    sumX = np.sum((eX), axis=0)\n",
    "    # other solution:\n",
    "    # return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    return eX/sumX\n",
    "\n",
    "logits = [3.0, 1.0, 2.0]\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax in TensorFlow\n",
    "TF provides a softmax implementation: **tf.nn.softmax()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65900117  0.24243298  0.09856589]\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed in the logit data\n",
    "        output = sess.run(softmax, feed_dict={logits:logit_data} )\n",
    "\n",
    "    return output\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding and Cross entropy evaluation\n",
    "The output probability from softmax is evaluated against One-Hot Encoding vectors through a Cross entropy function. This value is used as loss or cost to measure how well the model classifies the correct lable (high probability for the right label and low probability for the other labels).\n",
    "\n",
    "Cross entropy evaluation at TF is done with the help from **tf.reduce_sum()**, which sums all elements at an array and **tf.log()**.\n",
    "\n",
    "    Cross entropy function: D\n",
    "    Softmax output array: S\n",
    "    One hot enconded labels: L\n",
    "    D(S,L) = -sum(Li * log(Si))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross A:  0.356675\n"
     ]
    }
   ],
   "source": [
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "# TODO: Print cross entropy from session\n",
    "D = -tf.reduce_sum(one_hot * tf.log(softmax))\n",
    "with tf.Session() as sess:\n",
    "    print(\"Cross A: \", sess.run(D, feed_dict={softmax:softmax_data, one_hot:one_hot_data}))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch feature selection\n",
    "One technique to reduce the input size is to use mini-batch. The implementation of variable size arrays (mini-batch with variable size) is done with **None**:\n",
    "   \n",
    "    features = tf.placeholder(tf.float32, [None, n_input])\n",
    "    labels = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['F11', 'F12', 'F13', 'F14'], ['F21', 'F22', 'F23', 'F24'], ['F31', 'F32', 'F33', 'F34']]\n",
      "--\n",
      "[['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]\n",
      "[['F41', 'F42', 'F43', 'F44']]\n",
      "--\n",
      "[['L41', 'L42']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    # pass\n",
    "    output_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "    return output_batches\n",
    "\n",
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "# PPrint prints data structures like 2d arrays, so they are easier to read\n",
    "outputb = batches(3, example_features, example_labels)\n",
    "for b_f, b_l in outputb:\n",
    "    print(b_f)\n",
    "    print(\"--\")\n",
    "    print(b_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
